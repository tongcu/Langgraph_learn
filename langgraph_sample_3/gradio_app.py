import re 
import gradio as gr
import asyncio
import hashlib
from uuid import UUID
from langgraph_sdk import get_client
hostname = "http://langgraph-api-learn-2026-pre1231:2024"
# GRAPH_ID = "my_agent"
if hostname is None:
    API_URL = "http://127.0.0.1:2024"
else:
    API_URL = hostname

GRAPH_ID = "my_agent"

def name_to_uuid(name: str) -> str:
    """å°†æ™®é€šå­—ç¬¦ä¸²è½¬ä¸º 0.5.39 ç‰ˆæœ¬å¼ºåˆ¶è¦æ±‚çš„ UUID æ ¼å¼"""
    hash_obj = hashlib.md5(name.encode('utf-8'))
    return str(UUID(hash_obj.hexdigest()))

def format_ai_response(text: str) -> str:
    """
    å¦‚æœå­˜åœ¨ <think> æ ‡ç­¾ï¼Œå°†å…¶åŒ…è£…åœ¨æŠ˜å æ¡†å†…ï¼›
    å¦‚æœæ²¡æœ‰ï¼Œåˆ™ç›´æ¥è¾“å‡ºç»“æœã€‚
    """
    if not text: return ""
    
    pattern = r'<(?:think|thought)>(.*?)</(?:think|thought)>'
    match = re.search(pattern, text, flags=re.DOTALL)
    
    if match:
        thought_content = match.group(1).strip()
        # ç§»é™¤æ­£æ–‡ä¸­çš„ think éƒ¨åˆ†
        answer_content = re.sub(pattern, '', text, flags=re.DOTALL).strip()
        return f"<details><summary><b>ğŸ” æ€è€ƒè¿‡ç¨‹ (ç‚¹å‡»å±•å¼€)</b></summary>\n\n{thought_content}\n\n</details>\n\n{answer_content}"
    
    return text


async def ensure_thread_exists(client, thread_id):
    """ç‹¬ç«‹åŠŸèƒ½ï¼šç¡®ä¿çº¿ç¨‹å­˜åœ¨ï¼Œä¸å­˜åœ¨åˆ™åˆ›å»º"""
    try:
        await client.threads.get(thread_id)
    except Exception:
        # å¦‚æœè·å–å¤±è´¥ï¼ˆ404ï¼‰ï¼Œåˆ™æ‰‹åŠ¨åˆ›å»º
        # 2026-01-04T05:38:12.152238Z [warning  ] POST /threads/40b9ce26-4c12-cd34-5f55-a803f9cdcfae/runs/stream 404 2ms [langgraph_api.server] api_revision=212ad47 api_variant=local_dev langgraph_api_version=0.5.39 latency_ms=2 method=POST path=/threads/{thread_id}/runs/stream path_params={'thread_id': '40b9ce26-4c12-cd34-5f55-a803f9cdcfae'} proto=1.1 query_string= req_header={} request_id=dc850bd1-3dff-45da-9b50-e150b25509f3 res_header={} route=/threads/{thread_id}/runs/stream status=404 thread_name=MainThread
        await client.threads.create(thread_id=thread_id)
        print(f"DEBUG: Created new thread: {thread_id}")


def extract_content_from_event(data):
    """
    ç‹¬ç«‹åŠŸèƒ½ï¼šä»ä¸åŒçš„æ•°æ®ç»“æ„ä¸­æå–æ–‡æœ¬å†…å®¹
    """
    content = ""
    if isinstance(data, list):
        # å¦‚æœæ˜¯åˆ—è¡¨ï¼Œé€šå¸¸åŒ…å«å¤šæ¡æ¶ˆæ¯æˆ–æ¶ˆæ¯ç‰‡æ®µ
        for m in data:
            if isinstance(m, dict) and "content" in m:
                content += m["content"]
            elif hasattr(m, "content"):
                content += m.content
    elif isinstance(data, dict):
        content = data.get("content", "")
    elif hasattr(data, "content"):
        content = data.content
    return content
    
# --- 2. æ ¸å¿ƒé¢„æµ‹é€»è¾‘ ---
async def predict(message, history, task_input, file_path):
    client = get_client(url=API_URL)
    thread_id = get_thread_id()
    
    # ç¡®ä¿çº¿ç¨‹å­˜åœ¨
    await ensure_thread_exists(client, thread_id)

    input_state = {
        "task": task_input, # æ»¡è¶³ä½  state["task"] çš„éœ€æ±‚
        "messages": [{"role": "user", "content": message}]
    }
    
    msg_cache = {}
    try:
        async for event in client.runs.stream(
            thread_id,
            GRAPH_ID,
            input=input_state,
            stream_mode="values", # å®æ—¶åŒæ­¥ State
        ):
            if event.event == "metadata" or not event.data:
                continue
            
            # è·å–æœ€æ–°çš„æ¶ˆæ¯åˆ—è¡¨
            data = event.data
            messages = data.get("messages", []) if isinstance(data, dict) else data
            
            if not messages:
                continue
                
            current_msg = messages[-1]
            msg_id = getattr(current_msg, "id", "default")
            
            # ä½¿ç”¨ç‹¬ç«‹æå–å‡½æ•°
            content = extract_content_from_event(current_msg)
            
            # æ›´æ–°ç¼“å­˜å¹¶è¾“å‡º
            msg_cache[msg_id] = content
            full_display = "".join(msg_cache.values())
            
            yield full_display
            
    except Exception as e:
        yield f"âŒ è¿è¡Œå¼‚å¸¸: {str(e)}"

def create_ui():
    with gr.Blocks() as demo:
        gr.Markdown("# LangGraph Agent æŠ¥å‘ŠåŠ©æ‰‹")
        
        with gr.Row():
            with gr.Column():
                # å¢åŠ ä¼šè¯ ID å­—æ®µï¼Œé»˜è®¤ä¸ºä½ çš„ gradio_user_session
                session_id = gr.Textbox(label="ä¼šè¯ ID (ç”¨äºè®°å¿†)", value="gradio_user_session")
                task_input = gr.Textbox(label="ä»»åŠ¡å†…å®¹", lines=3)
                file_upload = gr.File(label="ä¸Šä¼ é™„ä»¶")
                submit_btn = gr.Button("å‘é€è¯·æ±‚")
            
            with gr.Column():
                output_text = gr.Textbox(label="Agent å›å¤", lines=10)
                uuid_display = gr.Label(label="å½“å‰ Thread UUID")

        # å¤„ç†é€»è¾‘ï¼šå…ˆè®¡ç®— UUID å±•ç¤ºç»™ç”¨æˆ·ï¼Œå†è°ƒç”¨ API
        def update_uuid(name):
            return name_to_uuid(name)

        session_id.change(update_uuid, inputs=[session_id], outputs=[uuid_display])

        submit_btn.click(
            fn=predict,
            inputs=[task_input, file_upload, session_id],
            outputs=[output_text]
        )
    return demo
if __name__ == "__main__":
    # å¯åŠ¨ Gradio
    ui = create_ui()
    ui.launch(
        server_name="0.0.0.0",
        server_port=7860,
    )