import re 
import gradio as gr
import asyncio
import hashlib
from uuid import UUID
from langgraph_sdk import get_client
from langchain_core.messages import AIMessage, HumanMessage


hostname = "http://langgraph-api-learn-2026-pre1231:2024"
# GRAPH_ID = "my_agent"
if hostname is None:
    API_URL = "http://127.0.0.1:2024"
else:
    API_URL = hostname

GRAPH_ID = "my_agent"

def name_to_uuid(name: str) -> str:
    """å°†æ™®é€šå­—ç¬¦ä¸²è½¬ä¸º 0.5.39 ç‰ˆæœ¬å¼ºåˆ¶è¦æ±‚çš„ UUID æ ¼å¼"""
    hash_obj = hashlib.md5(name.encode('utf-8'))
    return str(UUID(hash_obj.hexdigest()))

def format_ai_response(text: str) -> str:
    """
    å¦‚æœå­˜åœ¨ <think> æ ‡ç­¾ï¼Œå°†å…¶åŒ…è£…åœ¨æŠ˜å æ¡†å†…ï¼›
    å¦‚æœæ²¡æœ‰ï¼Œåˆ™ç›´æ¥è¾“å‡ºç»“æœã€‚
    """
    if not text: return ""
    
    pattern = r'<(?:think|thought)>(.*?)</(?:think|thought)>'
    match = re.search(pattern, text, flags=re.DOTALL)
    
    if match:
        thought_content = match.group(1).strip()
        # ç§»é™¤æ­£æ–‡ä¸­çš„ think éƒ¨åˆ†
        answer_content = re.sub(pattern, '', text, flags=re.DOTALL).strip()
        return f"<details><summary><b>ğŸ” æ€è€ƒè¿‡ç¨‹ (ç‚¹å‡»å±•å¼€)</b></summary>\n\n{thought_content}\n\n</details>\n\n{answer_content}"
    
    return text


async def get_thread_status(session_id):
    """
    ç‹¬ç«‹åŠŸèƒ½ï¼šæ¢æµ‹æŒ‡å®š thread çš„å®æ—¶è¿è¡ŒèŠ‚ç‚¹
    """
    client = get_client(url=API_URL)
    thread_id = name_to_uuid(session_id)
    
    try:
        # è·å–å½“å‰ thread çš„æœ€æ–°çŠ¶æ€
        state = await client.threads.get_state(thread_id)
        
        if not state or not state.get("next"):
            return "âœ… å½“å‰æ²¡æœ‰æ­£åœ¨è¿è¡Œæˆ–ç­‰å¾…çš„ä»»åŠ¡ã€‚"
        
        # next å­—æ®µåŒ…å«äº†å³å°†æ‰§è¡Œæˆ–æ­£åœ¨æ‰§è¡Œçš„èŠ‚ç‚¹åç§°
        current_nodes = state["next"]
        values = state.get("values", {})
        
        status_report = f"ğŸ“ **å½“å‰åœæ»ä½ç½®**: {current_nodes}\n"
        status_report += f"ğŸ“ **æ¶ˆæ¯æ€»æ•°**: {len(values.get('messages', []))} æ¡\n"
        
        if "task" in values:
            status_report += f"ğŸ“„ **ä¸Šä¸‹æ–‡çŠ¶æ€**: å·²åŠ è½½ (é•¿åº¦: {len(values['task'])})\n"
            
        return status_report
    except Exception as e:
        return f"âŒ æ— æ³•è·å–çŠ¶æ€: {str(e)}"

# async def ensure_thread_exists(client, thread_id):
#     """ç‹¬ç«‹åŠŸèƒ½ï¼šç¡®ä¿çº¿ç¨‹å­˜åœ¨ï¼Œä¸å­˜åœ¨åˆ™åˆ›å»º"""
#     try:
#         await client.threads.get(thread_id)
#     except Exception:
#         # å¦‚æœè·å–å¤±è´¥ï¼ˆ404ï¼‰ï¼Œåˆ™æ‰‹åŠ¨åˆ›å»º
#         # 2026-01-04T05:38:12.152238Z [warning  ] POST /threads/40b9ce26-4c12-cd34-5f55-a803f9cdcfae/runs/stream 404 2ms [langgraph_api.server] api_revision=212ad47 api_variant=local_dev langgraph_api_version=0.5.39 latency_ms=2 method=POST path=/threads/{thread_id}/runs/stream path_params={'thread_id': '40b9ce26-4c12-cd34-5f55-a803f9cdcfae'} proto=1.1 query_string= req_header={} request_id=dc850bd1-3dff-45da-9b50-e150b25509f3 res_header={} route=/threads/{thread_id}/runs/stream status=404 thread_name=MainThread
#         await client.threads.create(thread_id=thread_id)
#         print(f"DEBUG: Created new thread: {thread_id}")


# def extract_content_from_event(data):
#     """
#     ç‹¬ç«‹åŠŸèƒ½ï¼šä»ä¸åŒçš„æ•°æ®ç»“æ„ä¸­æå–æ–‡æœ¬å†…å®¹
#     """
#     content = ""
#     if isinstance(data, list):
#         # å¦‚æœæ˜¯åˆ—è¡¨ï¼Œé€šå¸¸åŒ…å«å¤šæ¡æ¶ˆæ¯æˆ–æ¶ˆæ¯ç‰‡æ®µ
#         for m in data:
#             if isinstance(m, dict) and "content" in m:
#                 content += m["content"]
#             elif hasattr(m, "content"):
#                 content += m.content
#     elif isinstance(data, dict):
#         content = data.get("content", "")
#     elif hasattr(data, "content"):
#         content = data.content
#     return content
    
def extract_message_info(msg):
    """
    ç‹¬ç«‹åŠŸèƒ½ï¼šä»ä¸åŒæ ¼å¼çš„æ¶ˆæ¯ä¸­æå–è§’è‰²ã€å†…å®¹å’Œå·¥å…·è°ƒç”¨ã€‚
    æ”¯æŒ LangChain å¯¹è±¡å’ŒåŸå§‹å­—å…¸æ ¼å¼ã€‚
    """
    if isinstance(msg, dict):
        role = msg.get("role", "")
        content = msg.get("content", "")
        tool_calls = msg.get("tool_calls", [])
    else:
        role = getattr(msg, "type", "")  # LangChain å¯¹è±¡é€šå¸¸ç”¨ type æ ‡è¯†
        content = getattr(msg, "content", "")
        tool_calls = getattr(msg, "tool_calls", [])
    
    return role, content, tool_calls

def get_tool_display_text(tool_calls):
    """
    ç‹¬ç«‹åŠŸèƒ½ï¼šå°†æŠ€æœ¯æ€§çš„ tool_calls è½¬æ¢ä¸ºç”¨æˆ·å‹å¥½çš„ä¸­æ–‡æç¤ºã€‚
    """
    if not tool_calls:
        return ""
    
    mapping = {
        "summarize_general": "ğŸ“ æ­£åœ¨æ·±åº¦åˆ†ææ–‡ç« å¹¶ç”Ÿæˆæ€»ç»“...",
        "web_search": "ğŸ” æ­£åœ¨æ£€ç´¢äº’è”ç½‘å®æ—¶ä¿¡æ¯...",
        # åœ¨æ­¤æ·»åŠ æ›´å¤šå·¥å…·åæ˜ å°„
    }
    
    hints = []
    for tool in tool_calls:
        # å…¼å®¹ä¸åŒç»“æ„çš„ tool_call
        name = tool.get("name") if isinstance(tool, dict) else tool.get("function", {}).get("name", "")
        hints.append(mapping.get(name, f"ğŸ› ï¸ æ­£åœ¨è°ƒç”¨å·¥å…· [{name}] å¤„ç†ä¸­..."))
    
    return "\n\n".join(hints)

# --- 2. é‡æ„åçš„æ ¸å¿ƒé¢„æµ‹é€»è¾‘ ---
async def predict(message, history, task_context, session_id, file_obj):
    client = get_client(url=API_URL)
    thread_id = name_to_uuid(session_id)
    
    # ç¡®ä¿çº¿ç¨‹å­˜åœ¨
    try:
        await client.threads.get(thread_id)
    except:
        await client.threads.create(thread_id=thread_id)
        print(f"INFO: Created new thread: {thread_id}")

    # æ„é€ è¾“å…¥çŠ¶æ€
    input_state = {
        "task": task_context,
        "messages": [{"role": "user", "content": message}]
    }
    
    if file_obj is not None:
        input_state["files"] = [file_obj.name]

    status_prefix = ""  # ç”¨äºå­˜å‚¨å·¥å…·è°ƒç”¨çš„ä¸­é—´çŠ¶æ€
    last_yielded_content = ""

    try:
        async for event in client.runs.stream(
            thread_id,
            GRAPH_ID,
            input=input_state,
            stream_mode="values", 
            config={
                "configurable": {},
                "recursion_limit": 50,    # é€’å½’æ·±åº¦é™åˆ¶
                "concurrency_limit": 1    # å•ä¸ª Run å†…éƒ¨å¹¶è¡Œçš„åˆ†æ”¯æ•°é™åˆ¶
                }
        ):
            if event.event == "metadata" or not event.data:
                continue
            
            data = event.data
            # stream_mode="values" è¿”å›çš„æ˜¯å…¨é‡æ¶ˆæ¯åˆ—è¡¨
            messages = data.get("messages", []) if isinstance(data, dict) else data
            if not messages:
                continue
            
            # æ‰¾åˆ°æœ€åä¸€æ¡æœ‰æ•ˆçš„ AI æ¶ˆæ¯
            # æ³¨æ„ï¼šæˆ‘ä»¬è¦ä»åå¾€å‰æ‰¾ï¼Œå› ä¸ºæœ€åä¸€æ¡å¯èƒ½æ˜¯ ToolMessage æˆ– UserMessage
            for msg in reversed(messages):
                role, content, tool_calls = extract_message_info(msg)
                
                # æƒ…å†µ Aï¼šæ¨¡å‹æ­£åœ¨å†³å®šè°ƒç”¨å·¥å…·
                if tool_calls:
                    status_prefix = f"> {get_tool_display_text(tool_calls)}\n\n"
                    yield status_prefix
                    break # æ‰¾åˆ°æœ€æ–°çš„ tool_call å³å¯

                # æƒ…å†µ Bï¼šæ¨¡å‹ç»™å‡ºäº†æ­£å¼å›å¤ (assistant)
                elif role in ["assistant", "ai"] and content:
                    # åªæœ‰å½“å†…å®¹çœŸæ­£æ›´æ–°æ—¶æ‰ yieldï¼Œé¿å… Gradio ç•Œé¢æŠ–åŠ¨
                    full_response = status_prefix + format_ai_response(content)
                    if full_response != last_yielded_content:
                        last_yielded_content = full_response
                        yield full_response
                    break # æ‰¾åˆ°æœ€æ–°çš„æœ‰æ•ˆå›å¤å³å¯
                
                # æƒ…å†µ Cï¼šå¦‚æœæ˜¯ç”¨æˆ·æ¶ˆæ¯ï¼Œæˆ‘ä»¬å¿½ç•¥å®ƒï¼ˆä¸æ¸²æŸ“åœ¨å›ç­”åŒºï¼‰ï¼Œç»§ç»­å‘ä¸Šæ‰¾
                else:
                    continue
                    
    except Exception as e:
        yield f"âŒ è¿è¡Œå¼‚å¸¸: {str(e)}"

def create_ui():
    with gr.Blocks(theme=gr.themes.Soft()) as demo:
        gr.Markdown("# ğŸ“‘ AI æ·±åº¦æŠ¥å‘Šåˆ†æåŠ©æ‰‹")
        
        with gr.Row():
            # å·¦ä¾§é…ç½®åŒº
            with gr.Column(scale=1):
                session_id = gr.Textbox(label="ä¼šè¯ ID", value="user_session_01")
                file_upload = gr.File(label="ä¸Šä¼ å‚è€ƒæ–‡æ¡£")
                # è¿™é‡Œçš„ task_context å¯¹åº”ä½ è¦æ±‚çš„ state["task"]
                task_context = gr.Textbox(
                    label="å¾…åˆ†æçš„æ–‡ç« /èƒŒæ™¯å†…å®¹", 
                    placeholder="åœ¨æ­¤ç²˜è´´é•¿ç¯‡æ–‡ç« ã€æ•°æ®æˆ–èƒŒæ™¯èµ„æ–™...",
                    lines=15
                )
            
            # å³ä¾§å¯¹è¯åŒº
            with gr.Column(scale=2):
                # ä½¿ç”¨ ChatInterface å¯ä»¥è‡ªåŠ¨å¤„ç† history é€»è¾‘
                chat = gr.ChatInterface(
                    fn=predict,
                    additional_inputs=[task_context, session_id, file_upload],
                    #type="messages" # ä½¿ç”¨æ–°çš„ messages æ ¼å¼
                )
                
    return demo

if __name__ == "__main__":
    # å¯åŠ¨ Gradio
    ui = create_ui()
    ui.launch(
        server_name="0.0.0.0",
        server_port=7860,
    )