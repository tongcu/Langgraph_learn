import re 
import gradio as gr
import asyncio
import hashlib
from uuid import UUID
from langgraph_sdk import get_client
from langchain_core.messages import AIMessage, HumanMessage
from graph.graph_manager import GraphManager, name_to_uuid # å¼•ç”¨ç‹¬ç«‹åŠŸèƒ½


hostname = "http://langgraph-api-learn-2026-pre1231:2024"
# GRAPH_ID = "my_agent"
if hostname is None:
    API_URL = "http://127.0.0.1:2024"
else:
    API_URL = hostname

# åˆå§‹åŒ–ç®¡ç†å™¨
graphmanager = GraphManager(api_url=API_URL)


GRAPH_ID = "my_agent"

def name_to_uuid(name: str) -> str:
    """å°†æ™®é€šå­—ç¬¦ä¸²è½¬ä¸º 0.5.39 ç‰ˆæœ¬å¼ºåˆ¶è¦æ±‚çš„ UUID æ ¼å¼"""
    hash_obj = hashlib.md5(name.encode('utf-8'))
    return str(UUID(hash_obj.hexdigest()))

def format_ai_response(text: str) -> str:
    """
    å¦‚æœå­˜åœ¨ <think> æ ‡ç­¾ï¼Œå°†å…¶åŒ…è£…åœ¨æŠ˜å æ¡†å†…ï¼›
    å¦‚æœæ²¡æœ‰ï¼Œåˆ™ç›´æ¥è¾“å‡ºç»“æœã€‚
    """
    if not text: return ""
    
    pattern = r'<(?:think|thought)>(.*?)</(?:think|thought)>'
    match = re.search(pattern, text, flags=re.DOTALL)
    
    if match:
        thought_content = match.group(1).strip()
        # ç§»é™¤æ­£æ–‡ä¸­çš„ think éƒ¨åˆ†
        answer_content = re.sub(pattern, '', text, flags=re.DOTALL).strip()
        return f"<details><summary><b>ğŸ” æ€è€ƒè¿‡ç¨‹ (ç‚¹å‡»å±•å¼€)</b></summary>\n\n{thought_content}\n\n</details>\n\n{answer_content}"
    
    return text


async def get_thread_status(session_id):
    """
    ç‹¬ç«‹åŠŸèƒ½ï¼šæ¢æµ‹æŒ‡å®š thread çš„å®æ—¶è¿è¡ŒèŠ‚ç‚¹
    """
    client = get_client(url=API_URL)
    thread_id = name_to_uuid(session_id)
    
    try:
        # è·å–å½“å‰ thread çš„æœ€æ–°çŠ¶æ€
        state = await client.threads.get_state(thread_id)
        
        if not state or not state.get("next"):
            return "âœ… å½“å‰æ²¡æœ‰æ­£åœ¨è¿è¡Œæˆ–ç­‰å¾…çš„ä»»åŠ¡ã€‚"
        
        # next å­—æ®µåŒ…å«äº†å³å°†æ‰§è¡Œæˆ–æ­£åœ¨æ‰§è¡Œçš„èŠ‚ç‚¹åç§°
        current_nodes = state["next"]
        values = state.get("values", {})
        
        status_report = f"ğŸ“ **å½“å‰åœæ»ä½ç½®**: {current_nodes}\n"
        status_report += f"ğŸ“ **æ¶ˆæ¯æ€»æ•°**: {len(values.get('messages', []))} æ¡\n"
        
        if "task" in values:
            status_report += f"ğŸ“„ **ä¸Šä¸‹æ–‡çŠ¶æ€**: å·²åŠ è½½ (é•¿åº¦: {len(values['task'])})\n"
            
        return status_report
    except Exception as e:
        return f"âŒ æ— æ³•è·å–çŠ¶æ€: {str(e)}"

# async def ensure_thread_exists(client, thread_id):
#     """ç‹¬ç«‹åŠŸèƒ½ï¼šç¡®ä¿çº¿ç¨‹å­˜åœ¨ï¼Œä¸å­˜åœ¨åˆ™åˆ›å»º"""
#     try:
#         await client.threads.get(thread_id)
#     except Exception:
#         # å¦‚æœè·å–å¤±è´¥ï¼ˆ404ï¼‰ï¼Œåˆ™æ‰‹åŠ¨åˆ›å»º
#         # 2026-01-04T05:38:12.152238Z [warning  ] POST /threads/40b9ce26-4c12-cd34-5f55-a803f9cdcfae/runs/stream 404 2ms [langgraph_api.server] api_revision=212ad47 api_variant=local_dev langgraph_api_version=0.5.39 latency_ms=2 method=POST path=/threads/{thread_id}/runs/stream path_params={'thread_id': '40b9ce26-4c12-cd34-5f55-a803f9cdcfae'} proto=1.1 query_string= req_header={} request_id=dc850bd1-3dff-45da-9b50-e150b25509f3 res_header={} route=/threads/{thread_id}/runs/stream status=404 thread_name=MainThread
#         await client.threads.create(thread_id=thread_id)
#         print(f"DEBUG: Created new thread: {thread_id}")


# def extract_content_from_event(data):
#     """
#     ç‹¬ç«‹åŠŸèƒ½ï¼šä»ä¸åŒçš„æ•°æ®ç»“æ„ä¸­æå–æ–‡æœ¬å†…å®¹
#     """
#     content = ""
#     if isinstance(data, list):
#         # å¦‚æœæ˜¯åˆ—è¡¨ï¼Œé€šå¸¸åŒ…å«å¤šæ¡æ¶ˆæ¯æˆ–æ¶ˆæ¯ç‰‡æ®µ
#         for m in data:
#             if isinstance(m, dict) and "content" in m:
#                 content += m["content"]
#             elif hasattr(m, "content"):
#                 content += m.content
#     elif isinstance(data, dict):
#         content = data.get("content", "")
#     elif hasattr(data, "content"):
#         content = data.content
#     return content
    
def extract_message_info(msg):
    """
    æè‡´å…¼å®¹ç‰ˆï¼šä»å„ç§æ¶ˆæ¯æ ¼å¼ä¸­æå–è§’è‰²ã€å†…å®¹å’Œå·¥å…·è°ƒç”¨ã€‚
    æ”¯æŒï¼š
    1. LangChain åŸå§‹å¯¹è±¡ (.type, .content)
    2. LangGraph åºåˆ—åŒ–å­—å…¸ (['type'], ['content'])
    3. æ ‡å‡† OpenAI å­—å…¸ (['role'], ['content'])
    """
    if not msg:
        return "", "", []

    # 1. æå–è§’è‰² (Role/Type)
    # ä¼˜å…ˆçº§ï¼šå­—å…¸çš„ type > å­—å…¸çš„ role > å¯¹è±¡çš„ typeå±æ€§
    if isinstance(msg, dict):
        role = msg.get("type") or msg.get("role") or ""
        content = msg.get("content", "")
        tool_calls = msg.get("tool_calls", [])
        
        # å…¼å®¹æ€§è¡¥ä¸ï¼šæœ‰äº›æ¨¡å‹ä¼šæŠŠ tool_calls å¡åœ¨ additional_kwargs é‡Œ
        if not tool_calls and "additional_kwargs" in msg:
            tool_calls = msg["additional_kwargs"].get("tool_calls", [])
    else:
        role = getattr(msg, "type", "")
        content = getattr(msg, "content", "")
        tool_calls = getattr(msg, "tool_calls", [])

    # 2. ä¿®æ­£ï¼šå¦‚æœ content ä¸ºç©ºå­—ç¬¦ä¸²ï¼Œä½†åœ¨ tool_calls é‡Œæœ‰ä¸œè¥¿ï¼Œ
    # æˆ‘ä»¬è®¤ä¸ºè¿™ä¹Ÿæ˜¯ä¸€ç§æœ‰æ•ˆçš„â€œå›å¤â€
    return role, content, tool_calls

# é€šç”¨ å·¥å…·å†…å®¹è¯»å–
def format_tool_args(args):
    """åŠ¨æ€æ ¼å¼åŒ–å·¥å…·å‚æ•°ä¸ºæ˜“è¯»çš„å­—ç¬¦ä¸²"""
    if not isinstance(args, dict):
        return str(args)
    
    parts = []
    for key, value in args.items():
        # å°†å­—æ®µåç¿»è¯‘æˆ–æ ¼å¼åŒ–ï¼ˆä¾‹å¦‚ summary -> æ‘˜è¦ï¼‰
        label = key.replace("_", " ").title() 
        
        if isinstance(value, list):
            # å¤„ç†åˆ—è¡¨ï¼ˆå¦‚ key_takeawaysï¼‰
            item_str = "\n   Â· ".join([str(i) for i in value])
            parts.append(f"ğŸ”¹ **{label}**:\n   Â· {item_str}")
        elif isinstance(value, dict):
            # å¤„ç†åµŒå¥—å­—å…¸
            parts.append(f"ğŸ”¹ **{label}**: {list(value.values())[0]}...")
        else:
            # å¤„ç†æ™®é€šå­—ç¬¦ä¸²
            # å¦‚æœå†…å®¹å¤ªé•¿ï¼Œå¯ä»¥åšä¸ªæˆªæ–­å±•ç¤º
            display_val = (str(value)[:100] + "...") if len(str(value)) > 100 else str(value)
            parts.append(f"ğŸ”¹ **{label}**: {display_val}")
            
    return "\n".join(parts)

def get_tool_display_text(tool_calls):
    """
    ç‹¬ç«‹åŠŸèƒ½ï¼šå°†æŠ€æœ¯æ€§çš„ tool_calls è½¬æ¢ä¸ºç”¨æˆ·å‹å¥½çš„ä¸­æ–‡æç¤ºã€‚
    """
    if not tool_calls:
        return ""
    
    mapping = {
        "summarize_general": "è°ƒç”¨å·¥å…· summarize_general æ­£åœ¨æ·±åº¦åˆ†ææ–‡ç« å¹¶ç”Ÿæˆæ€»ç»“...",
        "web_search": "ğŸ” æ­£åœ¨æ£€ç´¢äº’è”ç½‘å®æ—¶ä¿¡æ¯...",
        # åœ¨æ­¤æ·»åŠ æ›´å¤šå·¥å…·åæ˜ å°„
    }
    
    hints = []
    for tool in tool_calls:
        # å…¼å®¹ä¸åŒç»“æ„çš„ tool_call
        name = tool.get("name", "Unknown Tool")
        args = tool.get("args", {})
    
        # 1. è·å–åŸºæœ¬æç¤ºè¯­
        base_hint = mapping.get(name, f"ğŸ› ï¸ æ­£åœ¨æ‰§è¡Œ {name}...")
        # 2. åŠ¨æ€è·å–å‚æ•°è¯¦æƒ…
        detail_hint = format_tool_args(args)
        
        # 3. ç»„åˆ
        full_hint = f"{base_hint}\n\n{detail_hint[:100]}\n"
        hints.append(full_hint)
    
    return "\n\n".join(hints)

# --- 2. é‡æ„åçš„æ ¸å¿ƒé¢„æµ‹é€»è¾‘ ---
async def predict(message, history, task_context, session_id, file_obj):
    client = get_client(url=API_URL)
    thread_id = name_to_uuid(session_id)
    
    # ç¡®ä¿çº¿ç¨‹å­˜åœ¨
    try:
        await client.threads.get(thread_id)
    except:
        await client.threads.create(thread_id=thread_id)
        print(f"INFO: Created new thread: {thread_id}")

    # æ„é€ è¾“å…¥çŠ¶æ€
    input_state = {
        "task": task_context,
        "messages": [{"role": "user", "content": message}]
    }
    
    if file_obj is not None:
        input_state["files"] = [file_obj.name]

    status_prefix = ""  # ç”¨äºå­˜å‚¨å·¥å…·è°ƒç”¨çš„ä¸­é—´çŠ¶æ€
    last_yielded_content = ""

    try:
        async for event in client.runs.stream(
            thread_id,
            GRAPH_ID,
            input=input_state,
            # åŒæ—¶ç›‘å¬ values(çŠ¶æ€å…¨é‡) å’Œ updates(èŠ‚ç‚¹è¿è¡Œè½¨è¿¹)
            stream_mode=["values", "updates"],
            # config={
            #     "configurable": {},
            #     "recursion_limit": 50,    # é€’å½’æ·±åº¦é™åˆ¶
            #     "concurrency_limit": 1    # å•ä¸ª Run å†…éƒ¨å¹¶è¡Œçš„åˆ†æ”¯æ•°é™åˆ¶
            #     }
        ):
            # print(f"DEBUG FRONTEND: æ”¶åˆ°èŠ‚ç‚¹ {event.data} çš„æ›´æ–°")
            print(f"DEBUG FRONTEND: æ”¶åˆ°eventèŠ‚ç‚¹ {event.event} çš„æ›´æ–°")
            if event.event == "metadata" or not event.data:
                # import pdb; pdb.set_trace()
                continue
            
           
            data = event.data
            # import pdb; pdb.set_trace()
            # stream_mode="values" è¿”å›çš„æ˜¯å…¨é‡æ¶ˆæ¯åˆ—è¡¨
            messages = data.get("messages", []) if isinstance(data, dict) else data
            if not messages:
                continue
            # import pdb; pdb.set_trace()
            # æ‰¾åˆ°æœ€åä¸€æ¡æœ‰æ•ˆçš„ AI æ¶ˆæ¯
            # æ³¨æ„ï¼šæˆ‘ä»¬è¦ä»åå¾€å‰æ‰¾ï¼Œå› ä¸ºæœ€åä¸€æ¡å¯èƒ½æ˜¯ ToolMessage æˆ– UserMessage
            for msg in reversed(messages):
                role, content, tool_calls = extract_message_info(msg)
                
                # --- ä¿®æ”¹åçš„é€»è¾‘ä¼˜å…ˆçº§ ---
                # import pdb; pdb.set_trace()
                # 1. ä¼˜å…ˆæ£€æŸ¥ï¼šå¦‚æœæ˜¯ AI ä¸”æœ‰å®è´¨æ€§å†…å®¹ï¼Œè¿™æ˜¯æœ€ç»ˆç­”æ¡ˆæˆ–é˜¶æ®µæ€§ç­”æ¡ˆ
                if role in ["assistant", "ai"] and content.strip():
                    # å¦‚æœæœ‰ contentï¼Œæˆ‘ä»¬å±•ç¤ºå†…å®¹ã€‚
                    # å¦‚æœåŒæ—¶æœ‰ tool_callsï¼ˆæŸäº›æ¨¡å‹ä¼šå¤ç°ï¼‰ï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥æŠŠ prefix åŠ ä¸Š
                    prefix = f"> {get_tool_display_text(tool_calls)}\n\n" if tool_calls else ""
                    full_response = prefix + format_ai_response(content)
                    
                    if full_response != last_yielded_content:
                        last_yielded_content = full_response
                        yield full_response
                    break # æ‰¾åˆ°æœ€æ–°çš„æ–‡æœ¬å›å¤ï¼Œé€€å‡ºå¾ªç¯

                # 2. æ¬¡è¦æ£€æŸ¥ï¼šå¦‚æœæ²¡æœ‰ content ä½†æœ‰ tool_callsï¼Œè¯´æ˜æ­£åœ¨è°ƒç”¨å·¥å…·é€”ä¸­
                elif tool_calls:
                    
                    new_status = f"> {get_tool_display_text(tool_calls)}\n\n"
                    if new_status != status_prefix:
                        status_prefix = new_status
                        yield status_prefix
                    break 

                # 3. å¦‚æœæ˜¯ ToolMessage æˆ–å…¶ä»–ï¼Œç»§ç»­å‘ä¸Šæ‰¾
                else:
                    continue
                    
    except Exception as e:
        yield f"âŒ è¿è¡Œå¼‚å¸¸: {str(e)}"

def create_ui():
    with gr.Blocks(theme=gr.themes.Soft()) as demo:
        gr.Markdown("# ğŸ“‘ AI æ·±åº¦æŠ¥å‘Šåˆ†æåŠ©æ‰‹")
        
        with gr.Row():
            with gr.Column(scale=1):
                session_id = gr.Textbox(label="ä¼šè¯ ID", value="user_session_01")
                
                # --- UI ä¸­æ˜¾ç¤ºç®¡ç†åŠŸèƒ½ ---
                with gr.Accordion("ğŸ› ï¸ çº¿ç¨‹é«˜çº§ç®¡ç†", open=True):
                    with gr.Row():
                        monitor_btn = gr.Button("ğŸ” ç›‘æ§çŠ¶æ€", size="sm")
                        clear_this_btn = gr.Button("ğŸ—‘ï¸ æ¸…ç†å½“å‰", size="sm")
                    
                    status_box = gr.Markdown("ğŸŸ¢ ç­‰å¾…æŒ‡ä»¤")
                    
                    with gr.Accordion("ğŸš¨ å±é™©æ“ä½œ", open=False):
                        clear_all_btn = gr.Button("ğŸ”¥ æ¸…ç©ºå…¨åº“çº¿ç¨‹", variant="stop")

                file_upload = gr.File(label="å‚è€ƒæ–‡æ¡£")
                task_context = gr.Textbox(label="åˆ†æèƒŒæ™¯", lines=10)

            with gr.Column(scale=2):
                chat = gr.ChatInterface(
                    fn=predict,
                    additional_inputs=[task_context, session_id, file_upload],
                )

        # --- ç»‘å®šç‹¬ç«‹å‡ºæ¥çš„åŠŸèƒ½ ---
        monitor_btn.click(
            fn=graphmanager.monitor_thread_state,
            inputs=[session_id],
            outputs=[status_box]
        )
        
        clear_this_btn.click(
            fn=graphmanager.clear_specific_thread,
            inputs=[session_id],
            outputs=[status_box]
        )
        
        clear_all_btn.click(
            fn=graphmanager.clear_all_threads,
            outputs=[status_box]
        )
                
    return demo

if __name__ == "__main__":
    # å¯åŠ¨ Gradio
    ui = create_ui()
    ui.launch(
        server_name="0.0.0.0",
        server_port=7860,
    )