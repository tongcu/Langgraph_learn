import re 
import gradio as gr
import asyncio
import hashlib
from uuid import UUID
from langgraph_sdk import get_client
from langchain_core.messages import AIMessage, HumanMessage
from graph.graph_manager import GraphManager # å¼•ç”¨ç‹¬ç«‹åŠŸèƒ½
from Utils.id import name_to_uuid_nr as name_to_uuid

# hostname = "http://langgraph-api-learn-2026-pre1231:2024"
# # GRAPH_ID = "my_agent"
# if hostname is None:
#     API_URL = "http://127.0.0.1:2024"
# else:
#     API_URL = hostname



from pages.format import format_tool_call_simple
from pages import render_admin_page
from config import settings
API_URL = settings.API_URL
# åˆå§‹åŒ–ç®¡ç†å™¨
graphmanager = GraphManager(api_url=API_URL)


GRAPH_ID = "my_agent"

def format_ai_response(text: str) -> str:
    """
    å¦‚æœå­˜åœ¨ <think> æ ‡ç­¾ï¼Œå°†å…¶åŒ…è£…åœ¨æŠ˜å æ¡†å†…ï¼›
    å¦‚æœæ²¡æœ‰ï¼Œåˆ™ç›´æ¥è¾“å‡ºç»“æœã€‚
    """
    if not text: return ""
    
    pattern = r'<(?:think|thought)>(.*?)</(?:think|thought)>'
    match = re.search(pattern, text, flags=re.DOTALL)
    
    if match:
        thought_content = match.group(1).strip()
        # ç§»é™¤æ­£æ–‡ä¸­çš„ think éƒ¨åˆ†
        answer_content = re.sub(pattern, '', text, flags=re.DOTALL).strip()
        return f"<details><summary><b> æ€è€ƒè¿‡ç¨‹ (ç‚¹å‡»å±•å¼€)</b></summary>\n\n{thought_content}\n\n</details>\n\n{answer_content}"
    
    return text


async def get_thread_status(session_id):
    """
    ç‹¬ç«‹åŠŸèƒ½ï¼šæ¢æµ‹æŒ‡å®š thread çš„å®æ—¶è¿è¡ŒèŠ‚ç‚¹
    """
    client = get_client(url=API_URL)
    thread_id = name_to_uuid(session_id)
    
    try:
        # è·å–å½“å‰ thread çš„æœ€æ–°çŠ¶æ€
        state = await client.threads.get_state(thread_id)
        
        if not state or not state.get("next"):
            return "âœ… å½“å‰æ²¡æœ‰æ­£åœ¨è¿è¡Œæˆ–ç­‰å¾…çš„ä»»åŠ¡ã€‚"
        
        # next å­—æ®µåŒ…å«äº†å³å°†æ‰§è¡Œæˆ–æ­£åœ¨æ‰§è¡Œçš„èŠ‚ç‚¹åç§°
        current_nodes = state["next"]
        values = state.get("values", {})
        
        status_report = f" **å½“å‰åœæ»ä½ç½®**: {current_nodes}\n"
        status_report += f" **æ¶ˆæ¯æ€»æ•°**: {len(values.get('messages', []))} æ¡\n"
        
        if "task" in values:
            status_report += f" **ä¸Šä¸‹æ–‡çŠ¶æ€**: å·²åŠ è½½ (é•¿åº¦: {len(values['task'])})\n"
            
        return status_report
    except Exception as e:
        return f"âŒ æ— æ³•è·å–çŠ¶æ€: {str(e)}"

    
def extract_message_info(msg):
    """
    æè‡´å…¼å®¹ç‰ˆï¼šä»å„ç§æ¶ˆæ¯æ ¼å¼ä¸­æå–è§’è‰²ã€å†…å®¹å’Œå·¥å…·è°ƒç”¨ã€‚
    æ”¯æŒï¼š
    1. LangChain åŸå§‹å¯¹è±¡ (.type, .content)
    2. LangGraph åºåˆ—åŒ–å­—å…¸ (['type'], ['content'])
    3. æ ‡å‡† OpenAI å­—å…¸ (['role'], ['content'])
    """
    if not msg:
        return "", "", []

    # 1. æå–è§’è‰² (Role/Type)
    # ä¼˜å…ˆçº§ï¼šå­—å…¸çš„ type > å­—å…¸çš„ role > å¯¹è±¡çš„ typeå±æ€§
    if isinstance(msg, dict):
        role = msg.get("type") or msg.get("role") or ""
        content = msg.get("content", "")
        tool_calls = msg.get("tool_calls", [])
        
        # å…¼å®¹æ€§è¡¥ä¸ï¼šæœ‰äº›æ¨¡å‹ä¼šæŠŠ tool_calls å¡åœ¨ additional_kwargs é‡Œ
        if not tool_calls and "additional_kwargs" in msg:
            tool_calls = msg["additional_kwargs"].get("tool_calls", [])
    else:
        role = getattr(msg, "type", "")
        content = getattr(msg, "content", "")
        tool_calls = getattr(msg, "tool_calls", [])

    # 2. ä¿®æ­£ï¼šå¦‚æœ content ä¸ºç©ºå­—ç¬¦ä¸²ï¼Œä½†åœ¨ tool_calls é‡Œæœ‰ä¸œè¥¿ï¼Œ
    # æˆ‘ä»¬è®¤ä¸ºè¿™ä¹Ÿæ˜¯ä¸€ç§æœ‰æ•ˆçš„â€œå›å¤â€
    return role, content, tool_calls

# --- 2. é‡æ„åçš„æ ¸å¿ƒé¢„æµ‹é€»è¾‘ ---
async def predict(message, history, model_selector, task_context, session_id, file_obj):
    client = get_client(url=API_URL)
    thread_id = name_to_uuid(session_id)
    # import pdb 
    # pdb.set_trace()
    # ç¡®ä¿çº¿ç¨‹å­˜åœ¨
    try:
        await client.threads.get(thread_id)
    except:
        await client.threads.create(thread_id=thread_id)
        print(f"INFO: Created new thread: {thread_id}")

    # æ„é€ è¾“å…¥çŠ¶æ€
    input_state = {
        "task": task_context,
        "messages": [{"role": "user", "content": message}],
        "task_id" : session_id
    }
    
    if file_obj is not None:
        input_state["files"] = [file_obj.name]

    status_prefix = ""  # ç”¨äºå­˜å‚¨å·¥å…·è°ƒç”¨çš„ä¸­é—´çŠ¶æ€
    last_yielded_content = ""
    run_config = {
        "configurable": {
            "model_name": model_selector  # å¯¹åº”ä½  node é‡Œçš„ key
        },
        "recursion_limit": 50
    }
    yielded_at_least_once = False # çŠ¶æ€æ ‡è®°
    try:
        async for event in client.runs.stream(
            thread_id,
            GRAPH_ID,
            input=input_state,
            # åŒæ—¶ç›‘å¬ values(çŠ¶æ€å…¨é‡) å’Œ updates(èŠ‚ç‚¹è¿è¡Œè½¨è¿¹)
            stream_mode=["values", "updates"],
            config=run_config
            # config={
            #     "configurable": {},
            #     "recursion_limit": 50,    # é€’å½’æ·±åº¦é™åˆ¶
            #     "concurrency_limit": 1    # å•ä¸ª Run å†…éƒ¨å¹¶è¡Œçš„åˆ†æ”¯æ•°é™åˆ¶
            #     }
        ):
            # print(f"DEBUG FRONTEND: æ”¶åˆ°èŠ‚ç‚¹ {event.data} çš„æ›´æ–°")
            print(f"DEBUG FRONTEND: æ”¶åˆ°eventèŠ‚ç‚¹ {event.event} çš„æ›´æ–°")
            if event.event == "metadata" or not event.data:
                # import pdb; pdb.set_trace()
                continue
            
           
            data = event.data
            # import pdb; pdb.set_trace()
            # stream_mode="values" è¿”å›çš„æ˜¯å…¨é‡æ¶ˆæ¯åˆ—è¡¨
            messages = data.get("messages", []) if isinstance(data, dict) else data
            if not messages:
                continue
            # import pdb; pdb.set_trace()

            # --- æ ¸å¿ƒä¿®æ”¹ï¼šç´¯åŠ æ‰€æœ‰ AI ç›¸å…³çš„è¡Œä¸º ---
            current_bubble_text = ""
            
            # é¡ºåºéå†ï¼ŒæŠŠè¿™æ¬¡ä»»åŠ¡ä¸­äº§ç”Ÿçš„æ‰€æœ‰å·¥å…·è°ƒç”¨å’Œå›å¤æ‹¼æ¥èµ·æ¥
            # æ³¨æ„ï¼šåªæ‹¼æ¥æœ€åä¸€æ¬¡ç”¨æˆ·è¾“å…¥ä¹‹åçš„ AI æ¶ˆæ¯
            found_last_user = False
            for msg in reversed(messages):
                role, content, tool_calls = extract_message_info(msg)
                
                # å¦‚æœç¢°åˆ°ç”¨æˆ·åˆšæ‰çš„æ¶ˆæ¯ï¼Œè¯´æ˜å¾€å‰çš„ AI æ¶ˆæ¯æ˜¯ä¸Šä¸€è½®çš„ï¼Œåœæ­¢æ‹¼æ¥
                if role == "human" or role == "user":
                    break
                
                # å¤„ç† AI æ¶ˆæ¯
                if role in ["assistant", "ai"]:
                    # 1. å¦‚æœæœ‰å·¥å…·è°ƒç”¨ï¼Œå…ˆæ‹¼ä¸Šå·¥å…·æç¤º
                    if tool_calls:
                        for call in tool_calls:
                            # è°ƒç”¨ä¸Šé¢å®šä¹‰çš„ç®€å•æ ¼å¼åŒ–å‡½æ•°
                            tool_text = format_tool_call_simple(call['name'], call['args'])
                            # æ‹¼æ¥åˆ°æ•´ä½“è¾“å‡ºçš„å‰é¢
                            if tool_text not in current_bubble_text:
                                current_bubble_text = tool_text + "\n" + current_bubble_text
                    
                    # 2. å¦‚æœæœ‰å†…å®¹å›å¤ï¼Œæ‹¼ä¸Šå†…å®¹
                    if content and content.strip():
                        current_bubble_text += format_ai_response(content)
            
            # åªæœ‰å†…å®¹å‘ç”Ÿå˜åŒ–æ‰ yield
            if current_bubble_text and current_bubble_text != last_yielded_content:
                print(f"DEBUG FRONTEND: role:{role} current_bubble_text\n: ** {current_bubble_text} çš„æ›´æ–°")
                last_yielded_content = current_bubble_text
                yielded_at_least_once = True
                yield current_bubble_text
        
        if not yielded_at_least_once:
            yield "..."
    except Exception as e:
        yield f"âŒ è¿è¡Œå¼‚å¸¸: {str(e)}"

def main_page():
        
    with gr.Row():
        with gr.Column(scale=1):
            # with gr.Row():
            # æ¨¡å‹é€‰æ‹©ä¸‹æ‹‰æ¡†

            session_id = gr.Textbox(label="ä¼šè¯ ID", value="user_session_01")
            
            # --- UI ä¸­æ˜¾ç¤ºç®¡ç†åŠŸèƒ½ ---
            with gr.Accordion("ğŸ› ï¸ çº¿ç¨‹é«˜çº§ç®¡ç†", open=True):
                with gr.Row():
                    monitor_btn = gr.Button("ğŸ” ç›‘æ§çŠ¶æ€", size="sm")
                    clear_this_btn = gr.Button("ğŸ—‘ï¸ æ¸…ç†å½“å‰", size="sm")
                
                status_box = gr.Markdown("ğŸŸ¢ ç­‰å¾…æŒ‡ä»¤")
                
                with gr.Accordion("ğŸš¨ å±é™©æ“ä½œ", open=False):
                    clear_all_btn = gr.Button("ğŸ”¥ æ¸…ç©ºå…¨åº“çº¿ç¨‹", variant="stop")
            
            # --- ğŸš€ æ­£ç¡®æ’å…¥ä½ç½®ï¼šå®æ—¶çŠ¶æ€å­—æ®µå†…å®¹ ---
            with gr.Accordion("ğŸ“Š å®æ—¶çŠ¶æ€å­—æ®µå†…å®¹", open=False):
                field_display_box = gr.Markdown("ç­‰å¾…æŸ¥è¯¢...")
                refresh_fields_btn = gr.Button("ğŸ”„ åˆ·æ–°å­—æ®µå†…å®¹", size="sm")

            file_upload = gr.File(label="å‚è€ƒæ–‡æ¡£")
            task_context = gr.Textbox(label="åˆ†æèƒŒæ™¯", lines=10)

        with gr.Column(scale=2):
            # æ¨¡å‹å‚æ•°æå–
            model_selector = gr.Dropdown(
                choices=["local_qwen_small", "local_qwen"], 
                value="local_qwen_small", 
                label="é€‰æ‹©æ¨¡å‹",
                interactive=True  # æ˜¾å¼å£°æ˜å¯äº¤äº’
            )
            chat = gr.ChatInterface(
                fn=predict,
                additional_inputs=[model_selector,task_context, session_id, file_upload],
                chatbot=gr.Chatbot(height=700, label="åˆ†æå¯¹è¯æµ"), 
                fill_height=False # è®¾ç½®ä¸º False åï¼Œheight æ‰ä¼šç”Ÿæ•ˆ
            )

            

    # --- ç»‘å®šç‹¬ç«‹å‡ºæ¥çš„åŠŸèƒ½ ---
    monitor_btn.click(
        fn=graphmanager.monitor_thread_state,
        inputs=[session_id],
        outputs=[status_box]
    )
    
    clear_this_btn.click(
        fn=graphmanager.clear_specific_thread,
        inputs=[session_id],
        outputs=[status_box]
    )
    
    clear_all_btn.click(
        fn=graphmanager.clear_all_threads,
        outputs=[status_box]
    )
    
    refresh_fields_btn.click(
        fn=graphmanager.monitor_specific_fields,
        inputs=[session_id],
        outputs=[field_display_box]
    )
                

def create_ui():
    with gr.Blocks(theme=gr.themes.Soft(), title="LangGraph åˆ†æä¸“å®¶") as demo:
        gr.Markdown("# ğŸ“‘ AI æ·±åº¦æŠ¥å‘Šåˆ†æåŠ©æ‰‹")
        
        with gr.Tabs() as tabs:
            # --- Tab 1: ç”¨æˆ·å¯¹è¯åŒº ---
            with gr.TabItem("â€œæ€»ç»“å¯¹è¯çª—å£", id=0):
                main_page()
            # --- Tab 2: åç«¯ç®¡ç†åŒº ---
            with gr.TabItem(" åº“ç®¡ç†ä¸ç›‘è§†", id=1):
                # è°ƒç”¨ç‹¬ç«‹å‡½æ•°ï¼Œä¼ å…¥ç®¡ç†å™¨å®ä¾‹
                render_admin_page(graphmanager)

    return demo

if __name__ == "__main__":
    # å¯åŠ¨ Gradio
    ui = create_ui()
    ui.launch(
        server_name="0.0.0.0",
        server_port=7860,
    )